apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "mlserver-sklearn-iris"
spec:
  predictor:
    model:
      modelFormat:
        name: sklearn
      storageUri: "gs://kfserving-examples/models/sklearn/1.0/model"
      runtime: kserve-mlserver
      resources:
        limits:
          cpu: 1
          memory: 500Mi
        requests:
          cpu: 250m
          memory: 250Mi
